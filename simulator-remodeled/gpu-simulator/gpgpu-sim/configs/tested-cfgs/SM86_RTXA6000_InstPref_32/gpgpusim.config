# Copyright (c) 2023-2025, Rodrigo Huerta, Mojtaba Abaie Shoushtary, Josep-Llorenç Cruz, Antonio González
# Universitat Politecnica de Catalunya
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# Redistributions of source code must retain the above copyright notice, this
# list of conditions and the following disclaimer.
# Redistributions in binary form must reproduce the above copyright notice,
# this list of conditions and the following disclaimer in the documentation
# and/or other materials provided with the distribution. Neither the name of
# The Universitat Politecnica de Catalunya nor the names of its contributors may be
# used to endorse or promote products derived from this software without
# specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.


-gpgpu_ptx_instruction_classification 0
-gpgpu_ptx_sim_mode 0
-gpgpu_ptx_force_max_capability 86

# Device Limits
-gpgpu_stack_size_limit 1024
-gpgpu_heap_size_limit 8388608
-gpgpu_runtime_sync_depth_limit 2
-gpgpu_runtime_pending_launch_count_limit 2048
-gpgpu_kernel_launch_latency 1500
-gpgpu_TB_launch_latency 0
-gpgpu_max_concurrent_kernel 128

# Compute Capability
-gpgpu_compute_capability_major 8
-gpgpu_compute_capability_minor 6

# PTX execution-driven
-gpgpu_ptx_convert_to_ptxplus 0
-gpgpu_ptx_save_converted_ptxplus 0

# high level architecture configuration
-gpgpu_n_clusters 84
-gpgpu_n_cores_per_cluster 1
-gpgpu_n_mem 24
-gpgpu_n_sub_partition_per_mchannel 2

# clock domains
#-gpgpu_clock_domains <Core Clock>:<Interconnect Clock>:<L2 Clock>:<DRAM Clock>
-gpgpu_clock_domains 1800:1800:1800:8000

# shader core pipeline config
-gpgpu_shader_registers 65536
-gpgpu_registers_per_block 65536
-gpgpu_occupancy_sm_number 86

# This implies a maximum of 48 warps/SM
-gpgpu_shader_core_pipeline 1536:32
-gpgpu_shader_cta 32
-gpgpu_simd_model 1

# Pipeline widths and number of FUs
# ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_pipeline_widths 4,4,4,4,4,4,4,4,4,4,8,4,4
-gpgpu_num_sp_units 4
-gpgpu_num_sfu_units 4
-gpgpu_num_int_units 4
-gpgpu_tensor_core_avail 1
-gpgpu_num_tensor_core_units 4

# Instruction latencies and initiation intervals
# "ADD,MAX,MUL,MAD,DIV"
# All Div operations are executed on SFU unit
-ptx_opcode_latency_int 4,4,4,4,21
-ptx_opcode_initiation_int 2,2,2,2,2
-ptx_opcode_latency_fp 4,4,4,4,39
-ptx_opcode_initiation_fp 2,2,2,2,2
-ptx_opcode_latency_dp 64,64,64,64,330
-ptx_opcode_initiation_dp 64,64,64,64,130
-ptx_opcode_latency_sfu 21
-ptx_opcode_initiation_sfu 8
-ptx_opcode_latency_tesnor 64
-ptx_opcode_initiation_tensor 64

# sub core model: in which each scheduler has its own register file and EUs
# i.e. schedulers are isolated
-gpgpu_sub_core_model 1
# disable specialized operand collectors and use generic operand collectors instead
-gpgpu_enable_specialized_operand_collector 0
-gpgpu_operand_collector_num_units_gen 8
-gpgpu_operand_collector_num_in_ports_gen 8
-gpgpu_operand_collector_num_out_ports_gen 8
# register banks
-gpgpu_num_reg_banks 8
-gpgpu_reg_file_port_throughput 2

# warp scheduling
-gpgpu_num_sched_per_core 4
-gpgpu_scheduler gto
# a warp scheduler issue mode
-gpgpu_max_insn_issue_per_warp 1
-gpgpu_dual_issue_diff_exec_units 1

## L1/shared memory configuration
# <nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>:<set_index_fn>,<mshr>:<N>:<merge>,<mq>:**<fifo_entry>
# ** Optional parameter - Required when mshr_type==Texture Fifo
# In adaptive cache, we adaptively assign the remaining shared memory to L1 cache 
# For more info, see https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory-7-x 
-gpgpu_adaptive_cache_config 1
-gpgpu_shmem_option 0,8,16,32,64,100
-gpgpu_unified_l1d_size 128
# L1 cache configuration
-gpgpu_l1_banks 4
-gpgpu_cache:dl1 S:4:128:256,L:T:m:L:L,A:384:48,32:0,32
-gpgpu_l1_banks_hashing_function 0

-gpgpu_gmem_skip_L1D 0
-gpgpu_flush_l1_cache 1
-gpgpu_flush_l2_cache 1
-gpgpu_n_cluster_ejection_buffer_size 32
-gpgpu_l1_cache_write_ratio 0

# shared memory  configuration
-gpgpu_shmem_size 102400
-gpgpu_shmem_sizeDefault 102400
-gpgpu_shmem_per_block 49152

# shared memory bankconflict detection 
-gpgpu_shmem_num_banks 32
-gpgpu_shmem_limited_broadcast 0
-gpgpu_shmem_warp_parts 1
-gpgpu_coalesce_arch 86

# L2 cache
-gpgpu_cache:dl2 S:64:128:16,L:B:m:L:P,A:192:96,32:0,32
-gpgpu_cache:dl2_texture_only 0
-gpgpu_dram_partition_queues 64:64:64:64
-gpgpu_perf_sim_memcpy 1
-gpgpu_memory_partition_indexing 2

# 128 KB Inst.
-gpgpu_cache:il1 N:64:128:16,L:R:f:N:L,S:32:32,32
-gpgpu_inst_fetch_throughput 4
# 128 KB Tex
# Note, TEX is deprected since Volta, It is used for legacy apps only. Use L1D cache instead with .nc modifier or __ldg mehtod
-gpgpu_tex_cache:l1 N:4:128:256,L:R:m:N:L,T:512:8,128:2
# 64 KB Const
-gpgpu_const_cache:l1 N:4:64:8,L:R:f:N:L,S:32:32,32
-gpgpu_perfect_inst_const_cache 0

# interconnection
# use built-in local xbar
-network_mode 2
-icnt_in_buffer_limit 512
-icnt_out_buffer_limit 512
-icnt_subnets 2
-icnt_flit_size 40
-icnt_arbiter_algo 1

# memory partition latency config 
-gpgpu_l2_rop_latency 211
-dram_latency 243

# dram sched config
-gpgpu_dram_scheduler 1
-gpgpu_frfcfs_dram_sched_queue_size 224
-gpgpu_dram_return_queue_size 224

# dram model config
-gpgpu_n_mem_per_ctrlr 1
-gpgpu_dram_buswidth 2
-gpgpu_dram_burst_length 16
-dram_data_command_freq_ratio 4
-gpgpu_mem_address_mask 1
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS

# Mem timing 
-gpgpu_dram_timing_opt nbk=16:CCD=4:RRD=12:RCD=24:RAS=55:RP=24:RC=78:CL=24:WL=8:CDLR=10:WR=24:nbkgrp=4:CCDL=6:RTPL=4
-dram_dual_bus_interface 0

# select lower bits for bnkgrp to increase bnkgrp parallelism
-dram_bnk_indexing_policy 0
-dram_bnkgrp_indexing_policy 1

#-dram_seperate_write_queue_enable 1
#-dram_write_queue_size 64:56:32

# stat collection
-gpgpu_memlatency_stat 14 
-gpgpu_runtime_stat 500
-enable_ptx_file_line_stats 1
-visualizer_enabled 0

# tracing functionality
#-trace_enabled 1
#-trace_components WARP_SCHEDULER,SCOREBOARD
#-trace_sampling_core 0

# MOD. Begin. Added L0I.
-is_L0I_enabled 1
-max_request_allowed_to_L1I 1
-max_reply_allowed_from_L1I 1
-latency_L0_to_L1 39
-latency_L1_to_L0 39
-gpgpu_cache:il0 N:8:128:32,L:R:f:N:L,S:32:16,8
-gpgpu_subcore_const_cache:l0 N:4:64:2,L:R:f:N:L,S:32:32,32
# MOD. End

# MOD. Begin. Remodeling
-is_fetch_and_decode_improved 1
-is_extra_traces_enabled 1
-is_SM_remodeling_enabled 1
-num_subcores_in_SM 4
-is_remodeling_scoreboarding_enabled 0
-is_ibuffer_remodeled_enabled 1
-ibuffer_remodeled_size 3
-fetch_decode_width 1

-tensor_latency 32
-tensor_rate_per_cycle 2048
-branch_latency 2
-half_latency 3
-uniform_latency 2
-predicate_latency 13
-miscellaneous_queue_latency 2
-miscellaneous_no_queue_latency 1

-branch_initiation 1
-half_initiation 2
-uniform_initiation 2
-predicate_initiation 2
-miscellaneous_queue_initiation 2
-miscellaneous_no_queue_initiation 1

-miscellaneous_queue_size 3
-memory_subcore_queue_size 4
-memory_intermidiate_stages_subcore_unit 6
-memory_sm_prt_size 128
-sm_memory_unit_l1c_access_queue_size 1
-sm_memory_unit_l1t_access_queue_size 1
-sm_memory_unit_l1d_access_queue_size 1
-sm_memory_unit_shmem_access_queue_size 1
-sm_memory_unit_bypass_l1d_directly_go_to_l2_access_queue_size 1
-sm_memory_unit_miscellaneous_access_queue_size 1
-num_cycles_to_wait_to_dispatch_another_inst_from_subcore_to_sm_shared_pipeline_when_is_mem_inst 2
-num_cycles_to_wait_to_dispatch_another_inst_from_subcore_to_sm_shared_pipeline_when_is_dp_inst 1

-memory_maximum_coalescing_cycles 1
-offset_latency_firts_stage_memory_subcore 0
-memory_shared_memory_minimum_latency 7
-memory_shared_memory_extra_latency_ldsm_multiple_matrix 2
-memmory_max_concurrent_requests_shmem_per_sm 999999
-memmory_max_concurrent_requests_standard_per_sm 1024
-memory_l1d_minimum_latency 13
-memory_global_shared_latency_for_ldgsts 19
-memory_l1d_max_lookups_per_cycle_per_bank 4
-memory_subcore_extra_latency_load_shared_mem 2
-constant_cache_latency_at_sm_structure 11

-memory_num_scalar_units_per_subcore 8
-memory_subcore_link_to_sm_byte_size 128
-is_load_half_bandwidth_in_the_subcore_link_to_sm_enabled 1
-is_store_half_bandwidth_in_the_subcore_link_to_sm_enabled 1

-dp_sm_shared_queue_size 1
-dp_subcore_queue_size 3
-dp_shared_intermidiate_stages 6
-dp_subcore_max_latency 13
-is_dp_pipeline_shared_for_subcores 1
-is_fp32ops_allowed_in_int_pipeline 1

-is_const_cache_accessed_blocks_tracking_enabled 1
-is_global_memory_accesses_blocks_tracking_enabled 1
-is_num_virtual_pages_tracking_enabled 1
-virtual_page_size_in_bytes 2097152
-num_const_cache_cycle_misses_before_switch_to_other_warp 4
-num_cycles_issue_port_busy_after_imadwide 1
-num_stall_cycles_wait_after_bits_stall_0_and_yield 46
-num_cycles_to_stall_SM_at_gpu_memory_barrier 186
-num_cycles_to_stall_SM_at_system_memory_barrier 2900
-num_cycles_to_stall_SM_at_cta_memory_barrier 53

#Subcore parameters
-perfect_constant_cache 0
-perfect_instruction_cache 0
-ibuffer_coalescing 0
-invalidate_instruction_caches_at_kernel_end 1
-is_instruction_prefetching_enabled 1
-prefetch_per_stream_buffer_size 32
-prefetch_num_stream_buffers 1
-num_instruction_prefetches_per_cycle 1
-is_rf_cache_enabled 1
-max_operands_regular_register_file 4
-max_latency_regular_register_file_latency 24
-num_regular_register_file_read_ports_per_bank 1
-num_regular_register_file_write_ports_per_bank 1
-max_size_register_file_write_queue_for_fixed_latency_instructions 8
-max_pops_per_cycle_register_file_write_queue_for_fixed_latency_instructions 1
-num_threads_granularity_read_regular_register_file_dp_inst 32
-num_threads_granularity_read_regular_register_file_mem_inst 32
-num_threads_granularity_read_regular_register_file_sfu_inst 32
-num_threads_granularity_read_regular_register_file_other_inst 32
-num_cycles_needed_to_write_a_reg_from_sm_struct_to_subcore 2
# MOD. End

# MOD. Begin. Fix WAR at baseline. scoreboard_reads for solving war hazards in the baseline configuration parameters
-scoreboard_war_mode opc
-scoreboard_war_max_uses_per_reg 9999
-scoreboard_war_static_power 0
-scoreboard_war_dynamic_power 0
# MOD. End

-is_custom_omp_scheduler_enabled 1
-custom_omp_scheduler_ratio_to_dynamic 0.3

-filter_first_kernel_id 0
-filter_last_kernel_id 500

-measure_coalescing_potential_stats 0
-number_of_coalescers 4
-prt_selection_policy_string OLDEST
-number_of_clusters_for_prt_selection 16
-interwarp_coalescing_quanta_warppool_policy_miss_ratio_threshold 0.99
-is_interwarp_coalescing_enabled 0
-num_interwarp_coalescing_tables 1
-interwarp_coalescing_quanta 100000
-interwarp_coalescing_selection_policy_string OLDEST
-max_size_interwarp_coalescing_per_table 99999



